{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682f35ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import argsort\n",
    "from sympy.physics.quantum import Commutator, Dagger, Operator\n",
    "from sympy import *\n",
    "import numpy as np\n",
    "from IPython.display import display, Markdown, Latex, clear_output\n",
    "from sympy.printing.latex import LatexPrinter\n",
    "from useful import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c2dcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_sign(A):\n",
    "    str_A = str(A)\n",
    "    if str_A[0] == '-':\n",
    "        return -1\n",
    "    else: \n",
    "        return +1\n",
    "    \n",
    "def is_leaf(s):\n",
    "    return 1 if len(s.args[:])==0 else 0\n",
    "\n",
    "def can_expand(s):\n",
    "    if isinstance(s, Commutator):\n",
    "        a = 0\n",
    "    else:\n",
    "        l = len(s.args[:])\n",
    "        if l == 1:\n",
    "            a = 0\n",
    "        elif l == 0:\n",
    "            a = -1\n",
    "        else:\n",
    "            a = 1\n",
    "    return a\n",
    "\n",
    "def is_operator(s): # need to stop before leaf formed\n",
    "    if isinstance(s, Operator):\n",
    "        return 1\n",
    "    else:\n",
    "        if is_leaf(s):\n",
    "            return 0#-1\n",
    "        else:\n",
    "            s_arg = s.args[:]\n",
    "            if len(s_arg) == 1:\n",
    "                s_arg = [s]\n",
    "            for sa in s_arg:\n",
    "                if is_operator(sa):\n",
    "                    return 1\n",
    "        return 0\n",
    "    \n",
    "def are_operators(S):\n",
    "    ops = []\n",
    "    for s in S:\n",
    "        ops.append(is_operator(s))\n",
    "    return ops\n",
    "\n",
    "def print_if_op(S):\n",
    "    if not isinstance(S, list):\n",
    "        T = S.args\n",
    "        if len(T) == 1:\n",
    "            T = [S]\n",
    "    else: \n",
    "        T = S\n",
    "    for s in T:\n",
    "        print(is_operator(s), '|', s)\n",
    "            \n",
    "def Separate_Op(A ): # Tokens must be a list of strings\n",
    "    if can_expand(A):\n",
    "        if A.is_Mul:\n",
    "            counter = 0\n",
    "            As = A.args[:]\n",
    "            if len(As) == 1:\n",
    "                As = [A]\n",
    "            op_inds = []\n",
    "            rest_inds = []\n",
    "            for i, s in enumerate(As):\n",
    "                if is_operator(s) == 1:\n",
    "                    op_inds.append(i)\n",
    "                else:\n",
    "                    rest_inds.append(i)\n",
    "            #print(As, '|', op_inds)\n",
    "            A_op = Mul(*[As[op] for op in op_inds], evaluate=True)\n",
    "            A_coeff = Mul(*[As[rest] for rest in rest_inds], evaluate=True)\n",
    "            if sep_sign(A_op)==-1:\n",
    "                A_op = -A_op\n",
    "                A_coeff = -A_coeff\n",
    "        else:\n",
    "            A_op = []\n",
    "            A_coeff = []\n",
    "            B = A.args[:]\n",
    "            if len(B) <= 1:\n",
    "                B = [A]\n",
    "            for b in B:\n",
    "                op, coeff = Separate_Op(b )\n",
    "                if isinstance(op,list):\n",
    "                    for op1, coeff1 in zip(op,coeff):\n",
    "                        A_op.append(op1)\n",
    "                        A_coeff.append(coeff1)\n",
    "                else:\n",
    "                    A_op.append(op)\n",
    "                    A_coeff.append(coeff)\n",
    "    else:\n",
    "        if is_operator(A):\n",
    "            A_op = A\n",
    "            A_coeff = 1\n",
    "        else:\n",
    "            A_op = 1\n",
    "            A_coeff = A\n",
    "        if sep_sign(A_op)==-1:\n",
    "            A_op = -A_op\n",
    "            A_coeff = -A_coeff\n",
    "    return A_op, A_coeff\n",
    "\n",
    "def Commutator_Collect(A):\n",
    "    A_op, A_coeff = Separate_Op(A )\n",
    "    if not isinstance(A_op, list):\n",
    "        A_op = [A_op]\n",
    "    if not isinstance(A_coeff, list):\n",
    "        A_coeff = [A_coeff]\n",
    "    i = 0\n",
    "    A_op_str = [str(s) for s in A_op]\n",
    "    new_terms = [] \n",
    "    if len(A_op_str) > 0:\n",
    "        while len(A_op_str) > 0:\n",
    "            c_str = A_op_str[i]\n",
    "            i_list = [i]\n",
    "            for j in range(i+1,len(A_op_str)):\n",
    "                d_str = A_op_str[j]\n",
    "                if c_str == d_str:\n",
    "                    i_list.append(j)\n",
    "            # Sum up relevant terms\n",
    "            curr_coeff = [A_coeff[j] for j in i_list if not A_coeff[j]==0]\n",
    "            Curr = factor(simplify(Add(*curr_coeff, evaluate = True)))\n",
    "            new_terms.append(Mul(Curr, A_op[i], evaluate = True))\n",
    "            # Remove used up terms\n",
    "            while len(i_list) > 0:\n",
    "                A_op.pop(i_list[-1])\n",
    "                A_op_str.pop(i_list[-1])\n",
    "                A_coeff.pop(i_list[-1])\n",
    "                i_list.pop(-1)\n",
    "        C =  Add(*new_terms)#, evaluate=False)\n",
    "    else:\n",
    "        C = A\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0213951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(A):\n",
    "    L = []\n",
    "    for a in A:\n",
    "        if isinstance(a, list):\n",
    "            a_flat = flatten(a)\n",
    "            for a_fl in a_flat:\n",
    "                L.append(a_fl)\n",
    "        else:\n",
    "            L.append(a)\n",
    "    return L\n",
    "def Occurances_of(str_A, tokens):\n",
    "    if not isinstance(str_A, list):\n",
    "        if not isinstance(str_A, str):\n",
    "            str_A = str(str_A)\n",
    "        occurances = np.empty(len(tokens), dtype=int)\n",
    "        for i, token in enumerate(tokens):\n",
    "            occurances[i] = str_A.count(token)\n",
    "    else:\n",
    "        occurances = np.empty([len(str_A), len(tokens)], dtype=int)\n",
    "        for i, stra in enumerate(str_A):\n",
    "            occurances[i,:] = Occurances_of(stra, tokens)\n",
    "    return occurances\n",
    "\n",
    "def plus_sign(A):\n",
    "    if not isinstance(A, list):\n",
    "        A_str = str(A)\n",
    "        if A_str[0] == '-':\n",
    "            B = -A\n",
    "        else:\n",
    "            B = A\n",
    "    else:\n",
    "        B = A\n",
    "        for i, a in enumerate(A):\n",
    "            B[i] = plus_sign(a)\n",
    "    return B\n",
    "\n",
    "def total_plus_sign(A):\n",
    "    if not isinstance(A, list):\n",
    "        A_str = str(A)\n",
    "        if A_str[0] == '-':\n",
    "            tot_sign = -1\n",
    "            B = -A\n",
    "        else:\n",
    "            tot_sign = +1\n",
    "            B = A\n",
    "    else:\n",
    "        B = A\n",
    "        tot_sign = +1\n",
    "        for i, a in enumerate(A):\n",
    "            c_tot_sign, B[i] = total_plus_sign(a)\n",
    "            tot_sign = tot_sign*c_tot_sign\n",
    "    return tot_sign, B\n",
    "\n",
    "def remove_commutators(A):\n",
    "    B = []\n",
    "    for a in A:\n",
    "        astr = str(a)\n",
    "        if astr.count('[') == 0:\n",
    "            # is not a commutator\n",
    "            B.append(a)\n",
    "    return B\n",
    "\n",
    "def Group_Terms(D, max_braces = 2, group_rational = 0):\n",
    "    if D.is_Add:\n",
    "        # Split into terms\n",
    "        term_list = []\n",
    "        D_args = D.args[:]\n",
    "        if len(D_args) == 1: # Don't expand into leaves\n",
    "            D_args = [D]\n",
    "        len_D = len(D_args)\n",
    "        term_signs = np.empty(len_D, dtype=int)\n",
    "        for i, d in enumerate(D_args):\n",
    "            d_list = list(d.args[:])\n",
    "            if len(d_list) == 0:\n",
    "                d_list = [d]\n",
    "            tot_sign, d_list = total_plus_sign(d_list)\n",
    "            term_list.append(d_list)\n",
    "            term_signs[i] = tot_sign\n",
    "        flat_str = flatten(term_list)\n",
    "        unique_terms = list(set(flat_str))\n",
    "        #print(unique_terms)\n",
    "        len_unique = len(unique_terms)\n",
    "        # Count occurances and term lengths\n",
    "        term_lengths = np.zeros(len_unique, dtype = int)\n",
    "        occ_mat = np.zeros([len_D, len_unique], dtype = int)\n",
    "        for i, unique_term in enumerate(unique_terms):\n",
    "            term_lengths[i] = len(str(unique_term))  # Simplest measurement of complexity\n",
    "            for j in range(len_D):\n",
    "                occ_mat[j, i] = term_list[j].count(unique_term)\n",
    "        # Perform sub group terms\n",
    "        return Sub_Group_Terms(unique_terms, occ_mat, term_signs, max_braces, group_rational, adder = 0)\n",
    "    else:\n",
    "        return D # Nothing to do here\n",
    "    \n",
    "def Sub_Group_Terms(unique_terms, occ_mat, signs, max_braces=2,  group_rational = 0, adder = 0):\n",
    "    len_unique = occ_mat.shape[1]\n",
    "    if np.prod(occ_mat.shape) > 0:\n",
    "        max_occ_sum = max(occ_mat)\n",
    "        if max_braces > 0 and (len(occ_mat.shape) > 1 or  occ_mat.shape[0] > 1):\n",
    "            # Find max occurance\n",
    "            occ_sum = sum(occ_mat)\n",
    "            if group_rational == 0:\n",
    "                for i in range(len_unique):\n",
    "                    if unique_terms[i].is_Rational:\n",
    "                        occ_sum[i] = min(1,occ_sum[i])\n",
    "            max_ind = np.argmax(occ_sum)\n",
    "            max_occ_sum = max(occ_sum)\n",
    "            if max_occ_sum > 1:\n",
    "                # Separate in in and out groups\n",
    "                term_indexes = np.where(occ_mat[:,max_ind])[0]\n",
    "                remaining_indexes = np.where(1-occ_mat[:,max_ind])[0]\n",
    "                sub_occ_mat = occ_mat[term_indexes,:]\n",
    "                rem_occ_mat = occ_mat[remaining_indexes,:]\n",
    "                sub_signs = signs[term_indexes]\n",
    "                rem_signs = signs[remaining_indexes]\n",
    "                # Group terms\n",
    "                sub_occ_sum = sum(sub_occ_mat)\n",
    "                if group_rational == 0:\n",
    "                    for i in range(len_unique):\n",
    "                        if unique_terms[i].is_Rational:\n",
    "                            sub_occ_sum[i] = min(1,sub_occ_sum[i])\n",
    "                len_sub = len(term_indexes)\n",
    "                rem_occ_sum = sum(rem_occ_mat)\n",
    "                len_rem = len(remaining_indexes)\n",
    "                # Sub first\n",
    "                max_loc = np.where(sub_occ_sum==len_sub)[0]\n",
    "                reduced_terms = []\n",
    "                for i in range(len(max_loc)):\n",
    "                    reduced_terms.append(unique_terms[max_loc[i]]) \n",
    "                if np.all(sub_signs == -1):\n",
    "                    shared_term = -Mul(*reduced_terms, evaluate=True)\n",
    "                    sub_signs[:] = +1\n",
    "                else:\n",
    "                    shared_term = Mul(*reduced_terms, evaluate=True)\n",
    "                sub_occ_sum[max_loc] = 0\n",
    "                sub_occ_mat[:,max_loc] = 0\n",
    "                new_shared_term = Sub_Group_Terms(unique_terms, sub_occ_mat, sub_signs, max_braces-len(max_loc), group_rational, adder = 0)\n",
    "                if not new_shared_term == 1:\n",
    "                    shared_term = shared_term*(new_shared_term)\n",
    "                # Remaining second\n",
    "                new_rem_term = Sub_Group_Terms(unique_terms, rem_occ_mat, rem_signs, max_braces, group_rational, adder = 1)\n",
    "                if not new_rem_term == 0:\n",
    "                    shared_term = shared_term+new_rem_term\n",
    "        if max_braces <= 0 or max_occ_sum <= 1: #Add terms together in final inner brace\n",
    "            len_D = occ_mat.shape[0]\n",
    "            if len_D > 0:\n",
    "                c_occ = occ_mat[0,:]\n",
    "                locs = np.where(c_occ)[0]\n",
    "                shared_term = factor(signs[0]*unique_terms[locs[0]])\n",
    "                for j in range(1,len(locs)):\n",
    "                    shared_term = Mul(shared_term, unique_terms[locs[j]], evaluate=True)\n",
    "\n",
    "                for i in range(1,len_D):\n",
    "                    c_occ = occ_mat[i,:]\n",
    "                    locs = np.where(c_occ)[0]\n",
    "                    curr_term = factor(signs[i]*unique_terms[locs[0]])\n",
    "                    for j in range(1,len(locs)):\n",
    "                        curr_term = Mul(curr_term, unique_terms[locs[j]], evaluate=True)\n",
    "                    shared_term = shared_term + curr_term\n",
    "            else:\n",
    "                shared_term = 1 - adder\n",
    "    else:\n",
    "        shared_term = 1 - adder\n",
    "    return shared_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c0f2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Div(A, n):\n",
    "    if A.is_Add:\n",
    "        eq = []\n",
    "        B = A.args[:]\n",
    "        if len(B) <= 1: # Don't expand into leaves\n",
    "            B = [A]\n",
    "        for c in B:\n",
    "            eq.append(Rational('1/'+str(n))*c)\n",
    "        C = Add(*tuple(eq))\n",
    "    else:\n",
    "        C = Rational('1/'+str(n)) * A\n",
    "    return C\n",
    "\n",
    "def Multiply(A, n):\n",
    "    if A.is_Add:\n",
    "        eq = []\n",
    "        B = A.args[:]\n",
    "        if len(B) <= 1: # Don't expand into leaves\n",
    "            B = [A]\n",
    "        for b in B:\n",
    "            eq.append(n*b)\n",
    "        C = Add(*tuple(eq))\n",
    "    else:\n",
    "        C = n*A\n",
    "    return C\n",
    "\n",
    "def Minus(A):\n",
    "    if A.is_Add:\n",
    "        eq = []\n",
    "        B = A.args[:]\n",
    "        if len(B) <= 1: # Don't expand into leaves\n",
    "            B = [A]\n",
    "        for b in B:\n",
    "            eq.append(-b)\n",
    "        C = Add(*tuple(eq))\n",
    "    else:\n",
    "        C = -A\n",
    "    return C\n",
    "\n",
    "def Get_Order(A, tokens ): # Tokens must be a list of strings\n",
    "    if not A.is_Add:\n",
    "        counter = 0\n",
    "        A_str = str(A)\n",
    "        for token in tokens: #[1:]:  # start at 1 to avoid counting H0's\n",
    "            counter += A_str.count(token)\n",
    "    else:\n",
    "        counter = []\n",
    "        B = A.args[:]\n",
    "        if len(B) <= 1: # Don't expand into leaves\n",
    "            B = [A]\n",
    "        for b in B:\n",
    "            counter.append(Get_Order(b, tokens ))\n",
    "    return counter\n",
    "\n",
    "def Reduce2Order(A, max_deg, tokens):  # Also sorts the terms\n",
    "    counter = Get_Order(A, tokens )\n",
    "    if not A.is_Add:\n",
    "        if counter > max_deg:\n",
    "            B = 0\n",
    "        else:\n",
    "            B = A\n",
    "    else:\n",
    "        C = A.args[:]\n",
    "        if len(C) <= 1:\n",
    "            C = [A]\n",
    "        eq = []\n",
    "        for i, c in enumerate(counter):\n",
    "            if c <= max_deg:\n",
    "                eq.append(C[i])\n",
    "        B = Add(*eq, evaluate=False)\n",
    "    return B\n",
    "\n",
    "def Commutator_order(A,B, max_order, tokens):\n",
    "    a_order = Get_Order(A, tokens )\n",
    "    b_order = Get_Order(B, tokens )\n",
    "    if not A.is_Add:\n",
    "        al = [A]\n",
    "        a_order = [a_order]\n",
    "    else:\n",
    "        al = A.args[:]\n",
    "        if len(al) <= 1:\n",
    "            al = [A]\n",
    "    if not B.is_Add:\n",
    "        bl = [B]\n",
    "        b_order = [b_order]\n",
    "    else:\n",
    "        bl = B.args[:]\n",
    "        if len(bl) <= 1:\n",
    "            bl = [B]\n",
    "    terms = []\n",
    "    for ao, a in zip(a_order, al):\n",
    "        for bo, b in zip(b_order, bl):\n",
    "            if ao+bo <= max_order:\n",
    "                ab_ba = Commutator(a,b)\n",
    "                if not ab_ba == 0: \n",
    "                    terms.append(ab_ba)\n",
    "    C = Add(*list(terms))\n",
    "    return C\n",
    "\n",
    "def Multi_Commutator_order(C, max_order, tokens):\n",
    "    # C needs to be a list of commutators\n",
    "    n = len(C)\n",
    "    if n < 2:\n",
    "        print('Multi Commutator needs to be at least of length len(C) >= 2 to be considered a commutator. ')\n",
    "        raise ValueError\n",
    "    D = C.reverse()\n",
    "    E = Commutator_order(C[1], C[0], max_order, tokens) \n",
    "    for i in range(2, n):\n",
    "        E = Commutator_order(C[i], E, max_order, tokens) \n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1e1735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Separate_by_Order(C, tokens):\n",
    "    if C.is_Add:\n",
    "        a_s = C.args[:]\n",
    "        if len(a_s) <= 1:\n",
    "            a_s = [C]\n",
    "        o_s = zeros(len(a_s), dtype=int)\n",
    "        for i, a in enumerate(a_s):\n",
    "            o_s[i] = Get_Order(a, tokens)\n",
    "        o_max = max(o_s)\n",
    "        terms = [0]*(o_max+1)\n",
    "        for i, a in enumerate(a_s):\n",
    "            curr_o = o_s[i]\n",
    "            terms[curr_o] = terms[curr_o]+factor(a)\n",
    "        return terms\n",
    "    else:\n",
    "        return [C]\n",
    "\n",
    "def Connect_by_Order(Cs):\n",
    "    D = factor(Add(*Cs, evaluate=True))\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcf4c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_add(T):\n",
    "    if T.is_Add:\n",
    "        Ts = list(T.args[:])\n",
    "        n = len(Ts)\n",
    "        op = []\n",
    "        coeff = []\n",
    "        for i, A in enumerate(Ts):\n",
    "            curr_op, curr_coeff = Separate_Op(A)\n",
    "            op.append(curr_op)\n",
    "            coeff.append(curr_coeff)\n",
    "        n = len(op)\n",
    "        # Find equalities between operator combinations\n",
    "        a_eq_pm_b = np.zeros([n,n], dtype=int)\n",
    "        for i in range(n-1):\n",
    "            o = op[i]\n",
    "            for j in range(i+1,n):\n",
    "                p = op[j]\n",
    "                if simplify(o - p) == 0:\n",
    "                    a_eq_pm_b[i,j] = 1\n",
    "                    a_eq_pm_b[j,i] = 1\n",
    "                elif simplify(o  + p) == 0:\n",
    "                    a_eq_pm_b[i,j] = -1\n",
    "                    a_eq_pm_b[j,i] = -1\n",
    "        T_new_not_initialized = 1\n",
    "        while len(op) > 1:\n",
    "            inds = np.argwhere(a_eq_pm_b[0,:])[:,0]\n",
    "            anti_inds = np.argwhere(a_eq_pm_b[0,:] == 0)[1:,0]\n",
    "            coeff_inds = [coeff[0]]\n",
    "            for ind in inds:\n",
    "                coeff_inds.append(a_eq_pm_b[0,ind]*coeff[ind])\n",
    "            total_coeff = simplify(Add(*coeff_inds, evaluate=True))\n",
    "            if not total_coeff == 0:\n",
    "                combined = Mul(*[op[0], total_coeff], evaluate=True)\n",
    "                if T_new_not_initialized:\n",
    "                    T_new = combined.copy()\n",
    "                    T_new_not_initialized = 0\n",
    "                else:\n",
    "                    T_new = Add(*[T_new, combined], evaluate=True)\n",
    "            # Remove terms\n",
    "            a_eq_pm_b = a_eq_pm_b[np.ix_(anti_inds, anti_inds)]\n",
    "            inds = np.sort(inds)\n",
    "            inds = inds[::-1]\n",
    "            for ind in inds:\n",
    "                op.pop(ind)\n",
    "                coeff.pop(ind)\n",
    "            op.pop(0)\n",
    "            coeff.pop(0)\n",
    "        if len(op) == 1:\n",
    "            combined = Mul(*[op[0], coeff[0]], evaluate=True)\n",
    "            if T_new_not_initialized:\n",
    "                T_new = combined\n",
    "                T_new_not_initialized = 0\n",
    "            else:\n",
    "                T_new = Add(*[T_new, combined], evaluate=True)\n",
    "    if T_new_not_initialized:\n",
    "        T_new = 0\n",
    "    return T_new\n",
    "\n",
    "def Simplify_Commutator_Terms(D): # Go through the tree of terms\n",
    "    D_new = D.copy()\n",
    "    Dargs = list(D.args[:])\n",
    "    if D.is_Mul:\n",
    "        operator_indexes = np.where(are_operators(Dargs[:]))[0]\n",
    "        for op_ind in operator_indexes:\n",
    "            Dargs[op_ind] = Simplify_Commutator_Terms(Dargs[op_ind])\n",
    "        return Mul(*Dargs, evaluate=True)\n",
    "    elif D.is_Add: #Finally, the lowest level\n",
    "        T_new = simplify_add(D_new)\n",
    "        return T_new\n",
    "    else:\n",
    "        return D\n",
    "    \n",
    "def Solve_Commutator_Equalities(eq, tokens, optimize = 2):\n",
    "    C = Separate_by_Order(eq, tokens=tokens)\n",
    "    C_new = C.copy()\n",
    "    for i in range(len(C_new)):\n",
    "        curr_C = C[i]\n",
    "        if not curr_C == 0:\n",
    "            D = Group_Terms(curr_C, max_braces = optimize)\n",
    "            C_new[i] = D\n",
    "            if D.is_Add or D.is_Mul:\n",
    "                D_new = list(D.args[:])\n",
    "                operator_indexes = np.where(are_operators(D_new))[0]\n",
    "                for op_ind in operator_indexes:\n",
    "                    A = Simplify_Commutator_Terms(D_new[op_ind])\n",
    "                    D_new[op_ind] = A#Simplify_Commutator_Terms(D.args[op_ind]) \n",
    "                if D.is_Add:\n",
    "                    C_new[i] = Add(*D_new, evaluate=True)\n",
    "                elif D.is_Mul:\n",
    "                    C_new[i] = Mul(*D_new, evaluate=True)\n",
    "    return C_new\n",
    "\n",
    "def Cleanup(eq, tokens, optimize = 2):\n",
    "    return Solve_Commutator_Equalities(eq, tokens, optimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cbb6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BCH_Order(A, B, max_order, tokens): # BCH up to commutator order [,^3]\n",
    "    A = Reduce2Order(A, max_order, tokens)\n",
    "    B = Reduce2Order(B, max_order, tokens)\n",
    "    if max_order >= 2: # always limit to order 3\n",
    "        Comm = Div(Commutator_order(A,B, max_order, tokens),'2')                                 # -1j    --> if exp(-1j*H) -> instead, here we use exp(H)\n",
    "    if max_order >= 3:\n",
    "        Comm = Add(Comm, Div(Multi_Commutator_order([A+Minus(B), A, B], max_order, tokens), '12'))      # -\n",
    "    if max_order >=4:\n",
    "        Comm = Add(Comm, -Div(Multi_Commutator_order([B, A, A, B], max_order, tokens), '24'))    # 1j*\n",
    "    \n",
    "    C = Add(*[A, B, Comm], evaluate=True)\n",
    "    return C\n",
    "\n",
    "def BCH_OC(A, B, max_order, op_tokens):\n",
    "    C = BCH_Order(A, B, max_order, op_tokens)\n",
    "    D = Commutator_Collect(C) \n",
    "    # Add simplification step here .....\n",
    "    return D\n",
    "\n",
    "def Multi_BCH_OC(A_s, max_order, op_tokens):\n",
    "    n = len(A_s)\n",
    "    C = BCH_OC(A_s[0], A_s[1], max_order, op_tokens)\n",
    "    for i in range(2,n):\n",
    "        C = BCH_OC(C, A_s[i], max_order, op_tokens)\n",
    "    return C\n",
    "\n",
    "def Multi_BCH_Order(A_s, max_order, op_tokens):\n",
    "    n = len(A_s)\n",
    "    C = BCH_Order( A_s[0], A_s[1], max_order, op_tokens)\n",
    "    for i in range(2,n):\n",
    "        C = BCH_Order(C, A_s[i], max_order, op_tokens)\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e00358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findfirst(string, patterns):\n",
    "    i = -1\n",
    "    for p in patterns:\n",
    "        ind = string.find(p, 0)\n",
    "        if ind > -1:\n",
    "            if i == -1:\n",
    "                i = ind\n",
    "            elif ind < i:\n",
    "                i = ind\n",
    "    return i\n",
    "\n",
    "def findlast(string, patterns):\n",
    "    i = -1\n",
    "    for p in patterns:\n",
    "        ind = string.rfind(p)\n",
    "        if ind > i:\n",
    "            i = ind + len(p)\n",
    "    return i\n",
    "            \n",
    "def findall_frac(string, start, mid, end):\n",
    "    i_s = []\n",
    "    i_ml = []\n",
    "    i_mr = []\n",
    "    i_e = []\n",
    "    ind = 0\n",
    "    ls = len(start)\n",
    "    lm = len(mid)\n",
    "    while ind != -1:\n",
    "        ind = string.find(start, ind+1)\n",
    "        if ind != -1:\n",
    "            i_s.insert(0, ind+ls)\n",
    "            ind = string.find(mid, ind+1)\n",
    "            i_ml.insert(0, ind)\n",
    "            i_mr.insert(0, ind+lm)\n",
    "            ind = string.find(end, ind+1)\n",
    "            i_e.insert(0, ind)\n",
    "    return i_s, i_ml, i_mr, i_e\n",
    "\n",
    "def cut_out_fracs(eq_str, tokens = []):\n",
    "    i_s, i_ml, i_mr, i_e = findall_frac(eq_str, r'\\frac{', r'}{', r'}' )\n",
    "\n",
    "    for s, ml, mr, e in zip(i_s, i_ml, i_mr, i_e):\n",
    "        u, d = eq_str[s:ml], eq_str[mr:e] # upper and lower string\n",
    "        # Find commutators in upper string\n",
    "        operator_start = findfirst(u, ['\\left[', '['] + tokens)\n",
    "        operator_end = findlast(u, ['\\right]', ']'] + tokens)\n",
    "        if operator_end < operator_start:\n",
    "            operator_end = len(u)\n",
    "        if operator_start > -1:\n",
    "            op = u[operator_start:operator_end]\n",
    "            coeff = u[:operator_start]+u[operator_end:]\n",
    "            if len(coeff) == 0:\n",
    "                coeff = r'1'\n",
    "            new_coeff = coeff + '}{' + d \n",
    "            eq_str = eq_str[:s] + new_coeff + r'}' + op + eq_str[e+1:]\n",
    "    return eq_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380e1eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_eq2latex(eq):\n",
    "    if isinstance(eq, list):\n",
    "        for e in eq:\n",
    "            line()\n",
    "            simple_eq2latex(e)\n",
    "    else:\n",
    "        if not isinstance(eq, int):\n",
    "            if eq.is_Add:\n",
    "                eq_str = '$' + LatexPrinter(dict(order='none'))._print_Add(eq) + '$'\n",
    "            else:\n",
    "                eq_str = '$' + LatexPrinter(dict(order='none'))._print_Mul(eq) + '$'\n",
    "            display(Latex( eq_str ) )\n",
    "    \n",
    "def latex_eq_str(eq, tokens=[], optimize=0, by_order=0, exp=0, fracs = 1):\n",
    "    begin = r'\\begin{align}\\n'\n",
    "    end = r'\\n\\end{align}'\n",
    "    if exp == 1:\n",
    "        begin = begin + r'\\exp\\Big('\n",
    "        end = r'\\Big)' + end \n",
    "    stringer = r'' + begin\n",
    "    if len(tokens) > 0:\n",
    "        C = Cleanup(eq, tokens, optimize)\n",
    "        n_C = len(C)\n",
    "        end = r' + \\mathcal{O}[\\overset{(' + str(n_C) + ')}{,}]' + end\n",
    "        cstrings = []\n",
    "        for c in C:\n",
    "            if not c == 0:\n",
    "                if c.is_Add:\n",
    "                    cstrings.append(r'{}'.format(LatexPrinter(dict(order='none'))._print_Add(c)))\n",
    "                else:\n",
    "                    cstrings.append(r'{}'.format(LatexPrinter(dict(order='none'))._print_Mul(c)))\n",
    "        if by_order == 1:\n",
    "            inter_m = r' - \\\\ \\n' \n",
    "            inter_p = r' + \\\\ \\n' \n",
    "        else:\n",
    "            inter_m = ' ' \n",
    "            inter_p = ' + ' \n",
    "            \n",
    "        eq_str = cstrings[0]\n",
    "        for c in cstrings[1:]:\n",
    "            if len(c) > 0:\n",
    "                if c[0] == '-':\n",
    "                    eq_str = eq_str + inter_m + c\n",
    "                else:\n",
    "                    eq_str = eq_str + inter_p + c\n",
    "        stringer = stringer + eq_str\n",
    "    else:\n",
    "        if optimize > 0:\n",
    "            eq = Group_Terms(eq, max_braces = optimize)\n",
    "        if eq.is_Add:\n",
    "            stringer = stringer + LatexPrinter(dict(order='none'))._print_Add(eq)\n",
    "        else:\n",
    "            stringer = stringer + LatexPrinter(dict(order='none'))._print_Mul(eq) \n",
    "\n",
    "    stringer = stringer + end\n",
    "    stringer = '{}'.format(stringer)\n",
    "    stringer = stringer.replace('\\\\n', '\\n')\n",
    "    stringer = stringer.replace('H', '\\hat{H}')\n",
    "    if fracs:\n",
    "        stringer = cut_out_fracs(stringer, tokens)\n",
    "    return stringer\n",
    "    \n",
    "def latex_eq(eq, tokens=[], optimize=0, by_order=0, exp=0, fracs=1):\n",
    "    eq_str =  latex_eq_str(eq, tokens, optimize, by_order, exp, fracs)\n",
    "    display(Latex( eq_str ) )\n",
    "    \n",
    "def latex_eq_print(eq, tokens=[], optimize=0, by_order=0, exp=0, fracs=1):\n",
    "    eq_str =  latex_eq_str(eq, tokens, optimize, by_order, exp, fracs)\n",
    "    display(Latex( eq_str ) )\n",
    "    print(eq_str)\n",
    "    \n",
    "def show(eq_str):\n",
    "    display(Latex( eq_str ) )\n",
    "\n",
    "def print_show(eq_str):\n",
    "    display(Latex( eq_str ) )\n",
    "    print(eq_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fce72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Symbols\n",
    "from sympy import I\n",
    "o2 = 2\n",
    "o3 = 3\n",
    "o4 = 4\n",
    "a = ['H0', 'H1', 'H2', 'H3'] # \n",
    "oa2 = [o2, a]\n",
    "oa3 = [o3, a]\n",
    "oa4 = [o4, a]\n",
    "# add complex number i \n",
    "H0 = -I * Operator('H0')\n",
    "H1 = -I * Operator('H1')\n",
    "H2 = -I * Operator('H2')\n",
    "H3 = -I * Operator('H3')\n",
    "# multiply hamiltonians with complex number i\n",
    "alpha = Symbol('a1', commutative=True)\n",
    "beta = Symbol('a2', commutative=True)\n",
    "delta = Symbol('a3', commutative=True)\n",
    "c  = Symbol('c',  commutative=True) \n",
    "c1 = Symbol('c1', commutative=True)\n",
    "c2 = Symbol('c2', commutative=True)\n",
    "c3 = Symbol('c3', commutative=True)\n",
    "d1 = Symbol('d1', commutative=True)\n",
    "d2 = Symbol('d2', commutative=True)\n",
    "d3 = Symbol('d3', commutative=True)\n",
    "s = ['a1', 'a2', 'a3', 'c1', 'c2', 'c3', 'd1', 'd2', 'd3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9339f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D UI\n",
    "U0 = H0 + c1*H1\n",
    "U1 = U0 + d1*H1\n",
    "\n",
    "A = BCH_OC(U1, Minus(U0), *oa3)\n",
    "eq_1d = BCH_OC(Multiply(A, alpha), U0, *oa3)\n",
    "latex_eq_print( eq_1d, tokens=a, optimize=1, by_order=0, exp=1, fracs= 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761d443c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D UI (Symmetric)\n",
    "U0 = H0 + c1*H1\n",
    "U0_2 = Div(U0,'2')\n",
    "U1 = U0 + d1*H1\n",
    "\n",
    "A = Multiply(Multi_BCH_OC([Minus(U0_2),U1,Minus(U0_2)], *oa3), alpha)\n",
    "eq_1d_sym = Multi_BCH_OC([U0_2, A, U0_2], *oa3)\n",
    "latex_eq_print( eq_1d_sym, tokens=a, optimize=2, by_order=0, exp=1, fracs= 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8316fa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trotter 1D (with binning - not discussed in paper)\n",
    "f1 = (c1+alpha*d1)\n",
    "#f1 = c# + alpha*d1\n",
    "eq_1d_trotter = BCH_OC( H0, f1*H1, *oa2)\n",
    "latex_eq_print( eq_1d_trotter, tokens=a, optimize=2, by_order=0, exp=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef88c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strang 1D  (Split Step) (with binning - not discussed in paper)\n",
    "eq_1d_trotter_sym = Multi_BCH_OC( [f1H1/2, H0, f1*H1/2], *oa4)\n",
    "latex_eq_print( eq_1d_trotter_sym, tokens=a, optimize=2, by_order=0, exp=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed99fc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 2D #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e282bf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D UI \n",
    "h00 = H0+c1*H1+c2*H2\n",
    "dh01 = d1*H1\n",
    "dh10 = d2*H2\n",
    "U00 = h00\n",
    "U01 = h00+dh01\n",
    "U10 = h00+dh10\n",
    "\n",
    "A = Multiply(BCH_OC(U01, Minus(U00), *oa3), alpha)\n",
    "B = Multiply(BCH_OC(U10, Minus(U00), *oa3), beta)             \n",
    "eq_2d = Multi_BCH_OC([B, A, U00], *oa3)\n",
    "latex_eq_print( eq_2d, tokens=a, optimize=2, by_order=0, exp=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924b66bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0f6bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D UI symmetric\n",
    "U00_2 = Div(U00, 2)\n",
    "U01_2 = Div(U01, 2)\n",
    "U10_2 = Div(U10, 2)\n",
    "\n",
    "A = Multiply(Multi_BCH_OC( [Minus(U00_2), U01, Minus(U00_2)], *oa3),  alpha)\n",
    "BR = Multiply(BCH_OC( U10_2, Minus(U00_2), *oa3),beta)\n",
    "BL = Multiply(BCH_OC(Minus(U00_2),  U10_2, *oa3),beta)\n",
    "eq_2d_sym = Multi_BCH_OC([U00_2, BL, A, BR, U00_2], *oa3)\n",
    "latex_eq_print( eq_2d_sym, tokens=a, optimize=0, by_order=0, exp=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b42c627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trotter 2D\n",
    "f1 = c1 #(c1+alpha*d1)\n",
    "f2 = c2 #(c2+alpha*d2)\n",
    "eq_2d_trotter = Multi_BCH_OC( [ H0, f1*H1, f2*H2 ], *oa2)\n",
    "latex_eq_print( eq_2d_trotter, tokens=a, optimize=2, by_order=0, exp=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84aef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strang 2D\n",
    "A = Multi_BCH_OC( [ H0/2, f1*H1/2, f2*H2/2 ], *oa4)\n",
    "B = Multi_BCH_OC( [ f2*H2/2, f1*H1/2, H0/2 ], *oa4)\n",
    "eq_2d_trotter_sym = Multi_BCH_OC( [ B,A ], *oa4)\n",
    "latex_eq_print( eq_2d_trotter_sym, tokens=a, optimize=2, by_order=0, exp=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770d6759",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### 3D ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd224abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D UI\n",
    "U000 = H0+c1*H1+c2*H2+c3*H3\n",
    "dh001 = d1*H1\n",
    "dh010 = d2*H2\n",
    "dh100 = d3*H3\n",
    "U001 = U000+dh001\n",
    "U010 = U000+dh010\n",
    "U100 = U000+dh100\n",
    "\n",
    "A = Multiply(BCH_OC( U001, Minus(U000), *oa3), alpha)\n",
    "B = Multiply(BCH_OC( U010, Minus(U000), *oa3), beta)\n",
    "C = Multiply(BCH_OC( U100, Minus(U000), *oa3), delta)\n",
    "eq_3d = Multi_BCH_OC([ C, B, A, U000], *oa2)\n",
    "latex_eq_print( eq_3d, tokens=a, optimize=2, by_order=0, exp=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b9f716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D UI symmetric\n",
    "U000_2 = Div(U000, 2)\n",
    "U001_2 = Div(U001, 2)\n",
    "U010_2 = Div(U010, 2)\n",
    "U100_2 = Div(U100, 2)\n",
    "\n",
    "A = Multiply(Multi_BCH_OC( [Minus(U000_2), U001, Minus(U000_2)], *oa3), alpha)\n",
    "BR = Multiply(BCH_OC( U010_2, Minus(U000_2), *oa3),beta)\n",
    "BL = Multiply(BCH_OC(Minus(U000_2),  U010_2, *oa3),beta)\n",
    "CR = Multiply(BCH_OC( U100_2, Minus(U000_2), *oa3),delta)\n",
    "CL = Multiply(BCH_OC(Minus(U000_2),  U100_2, *oa3),delta)\n",
    "eq_3d_sym = Multi_BCH_OC([U000_2, CL, BL, A, BR, CR, U000_2], *oa3)\n",
    "latex_eq_print( eq_3d_sym, tokens=a, optimize=0, by_order=0, exp=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37385714",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strang 3D\n",
    "f1 = c1\n",
    "f2 = c2 \n",
    "f3 = c3 \n",
    "A = Multi_BCH_OC( [ H0/2, f1*H1/2, f2*H2/2 , f3*H3/2 ], *oa3)\n",
    "B = Multi_BCH_OC( [ f3*H3/2, f2*H2/2, f1*H1/2, H0/2 ], *oa3)\n",
    "eq_2d_trotter_sym = Multi_BCH_OC( [ B,A ], *oa3)\n",
    "latex_eq_print( eq_2d_trotter_sym, tokens=a, optimize=2, by_order=0, exp=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643d0ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "fcea4ade978be79c43ac22e97867dd8ddb713824b66d08d4e9716212bce9ca29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
